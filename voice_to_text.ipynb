{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# éŸ³è¨Šè½‰æ–‡å­—å·¥å…· (ä¸Šå‚³æª”æ¡ˆç‰ˆ)\n",
        "\n",
        "é€™å€‹ notebook å¯ä»¥ï¼š\n",
        "- ä¸Šå‚³éŸ³è¨Š/å½±ç‰‡æª”æ¡ˆ\n",
        "- ä½¿ç”¨ Whisper æ¨¡å‹å°‡éŸ³è¨Šè½‰æ›æˆä¸­æ–‡æ–‡å­—\n",
        "- æ”¯æ´å¤šç¨®æª”æ¡ˆæ ¼å¼\n",
        "- è¼¸å‡ºåŒ…å«æ™‚é–“æˆ³è¨˜çš„æ–‡å­—æª”\n",
        "\n",
        "## ä¿®æ”¹ä½¿ç”¨ GPU é‹ç®—\n",
        "åŸ·è¡Œéšæ®µ -> è®Šæ›´åŸ·è¡Œé¡å‹ -> é¸T4 GPU\n",
        "\n",
        "## ä½¿ç”¨æ–¹æ³•\n",
        "1. ä¾åºåŸ·è¡Œæ¯å€‹ cell\n",
        "2. ä¸Šå‚³ä½ çš„éŸ³è¨Š/å½±ç‰‡æª”æ¡ˆ\n",
        "3. ç­‰å¾…è™•ç†å®Œæˆå¾Œä¸‹è¼‰çµæœ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_packages"
      },
      "source": [
        "## 1. å®‰è£å¿…è¦å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_cell",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# å®‰è£æ‰€éœ€å¥—ä»¶\n",
        "!pip install openai-whisper\n",
        "!pip install torch torchvision torchaudio\n",
        "# ç¢ºä¿ FFmpeg å¯ç”¨ (Colab é€šå¸¸å·²ç¶“å®‰è£)\n",
        "!apt update && apt install -y ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "import_setup"
      },
      "source": [
        "## 2. åŒ¯å…¥å¥—ä»¶å’Œåˆå§‹è¨­å®š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_cell"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import glob\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# å»ºç«‹å¿…è¦è³‡æ–™å¤¾\n",
        "os.makedirs(\"./subtitles/\", exist_ok=True)\n",
        "os.makedirs(\"./uploads/\", exist_ok=True)\n",
        "\n",
        "print(\"è³‡æ–™å¤¾å»ºç«‹å®Œæˆï¼\")\n",
        "print(\"æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ï¼š\")\n",
        "print(\"éŸ³è¨Šï¼šmp3, wav, flac, m4a, ogg, wma, aac\")\n",
        "print(\"å½±ç‰‡ï¼šmp4, avi, mov, mkv, wmv, flv, webm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_model"
      },
      "source": [
        "## 3. è¼‰å…¥ Whisper æ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_cell"
      },
      "outputs": [],
      "source": [
        "# è¼‰å…¥ Whisper æ¨¡å‹ (ç¬¬ä¸€æ¬¡æœƒéœ€è¦ä¸‹è¼‰æ¨¡å‹æª”æ¡ˆ)\n",
        "print(\"æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹...\")\n",
        "model = whisper.load_model(\"medium\")\n",
        "print(\"æ¨¡å‹è¼‰å…¥å®Œæˆï¼\")\n",
        "\n",
        "# è¨­å®šè·¯å¾‘\n",
        "export_dir = \"./subtitles/\"\n",
        "upload_dir = \"./uploads/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "define_functions"
      },
      "source": [
        "## 4. å®šç¾©æ ¸å¿ƒå‡½æ•¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "functions_cell"
      },
      "outputs": [],
      "source": [
        "def create_txt(fn, verbose: bool = False):\n",
        "    \"\"\"å°‡éŸ³è¨Šæª”æ¡ˆè½‰æ›æˆæ–‡å­—æª”\"\"\"\n",
        "    print(f\"æ­£åœ¨è½‰æ›: {os.path.basename(fn)}\")\n",
        "    \n",
        "    try:\n",
        "        result = model.transcribe(fn, language=\"zh\", verbose=verbose)\n",
        "        \n",
        "        # ä¿®æ­£è·¯å¾‘åˆ†éš”ç¬¦è™Ÿå•é¡Œ (é©ç”¨æ–¼ä¸åŒä½œæ¥­ç³»çµ±)\n",
        "        filename = os.path.basename(fn)\n",
        "        # ç§»é™¤æ‰€æœ‰å¯èƒ½çš„å‰¯æª”å\n",
        "        base_name = filename.split('.')[0]\n",
        "        export_fn = os.path.join(export_dir, base_name + '.txt')\n",
        "        \n",
        "        def format_timestamp(seconds):\n",
        "            seconds = int(seconds)\n",
        "            minutes, seconds = divmod(seconds, 60)\n",
        "            hours, minutes = divmod(minutes, 60)\n",
        "            return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
        "        \n",
        "        with open(export_fn, \"w\", encoding=\"utf-8\") as file:\n",
        "            for segment in result[\"segments\"]:\n",
        "                start = format_timestamp(segment[\"start\"])\n",
        "                end = format_timestamp(segment[\"end\"])\n",
        "                text = segment[\"text\"]\n",
        "                file.write(f\"[{start} --> {end}] {text}\\n\")\n",
        "        \n",
        "        print(f\"âœ… è½‰æ›å®Œæˆ: {os.path.basename(export_fn)}\")\n",
        "        return export_fn\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ è½‰æ›å¤±æ•—: {os.path.basename(fn)}, éŒ¯èª¤: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_supported_files(directory):\n",
        "    \"\"\"å–å¾—æŒ‡å®šç›®éŒ„ä¸­æ‰€æœ‰æ”¯æ´çš„éŸ³è¨Š/å½±ç‰‡æª”æ¡ˆ\"\"\"\n",
        "    supported_extensions = [\n",
        "        # éŸ³è¨Šæ ¼å¼\n",
        "        '*.mp3', '*.wav', '*.flac', '*.m4a', '*.ogg', '*.wma', '*.aac',\n",
        "        # å½±ç‰‡æ ¼å¼\n",
        "        '*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv', '*.flv', '*.webm'\n",
        "    ]\n",
        "    \n",
        "    files = []\n",
        "    for ext in supported_extensions:\n",
        "        files.extend(glob.glob(os.path.join(directory, ext)))\n",
        "        files.extend(glob.glob(os.path.join(directory, ext.upper())))\n",
        "    \n",
        "    return files\n",
        "\n",
        "print(\"å‡½æ•¸å®šç¾©å®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_files"
      },
      "source": [
        "## 5. ä¸Šå‚³æª”æ¡ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_cell"
      },
      "outputs": [],
      "source": [
        "# æ¸…ç©ºä¸Šå‚³è³‡æ–™å¤¾\n",
        "if os.path.exists(upload_dir):\n",
        "    shutil.rmtree(upload_dir)\n",
        "os.makedirs(upload_dir, exist_ok=True)\n",
        "\n",
        "print(\"è«‹é¸æ“‡è¦ä¸Šå‚³çš„éŸ³è¨Š/å½±ç‰‡æª”æ¡ˆï¼š\")\n",
        "print(\"æ”¯æ´æ ¼å¼ï¼šmp3, wav, flac, m4a, ogg, wma, aac, mp4, avi, mov, mkv, wmv, flv, webm\")\n",
        "print(\"\\nâš ï¸  æ³¨æ„ï¼šå¯ä»¥ä¸€æ¬¡é¸æ“‡å¤šå€‹æª”æ¡ˆ\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# å°‡ä¸Šå‚³çš„æª”æ¡ˆç§»å‹•åˆ°æŒ‡å®šè³‡æ–™å¤¾\n",
        "for filename in uploaded.keys():\n",
        "    src = filename\n",
        "    dst = os.path.join(upload_dir, filename)\n",
        "    shutil.move(src, dst)\n",
        "    print(f\"âœ… å·²ä¸Šå‚³: {filename}\")\n",
        "\n",
        "print(f\"\\nğŸ“ ç¸½å…±ä¸Šå‚³äº† {len(uploaded)} å€‹æª”æ¡ˆ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "process_files"
      },
      "source": [
        "## 6. è™•ç†ä¸Šå‚³çš„æª”æ¡ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process_cell"
      },
      "outputs": [],
      "source": [
        "# å–å¾—æ‰€æœ‰æ”¯æ´çš„æª”æ¡ˆ\n",
        "uploaded_files = get_supported_files(upload_dir)\n",
        "\n",
        "if not uploaded_files:\n",
        "    print(\"âŒ æ²’æœ‰æ‰¾åˆ°æ”¯æ´çš„æª”æ¡ˆæ ¼å¼\")\n",
        "    print(\"è«‹ç¢ºèªä¸Šå‚³çš„æª”æ¡ˆæ˜¯ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š\")\n",
        "    print(\"éŸ³è¨Šï¼šmp3, wav, flac, m4a, ogg, wma, aac\")\n",
        "    print(\"å½±ç‰‡ï¼šmp4, avi, mov, mkv, wmv, flv, webm\")\n",
        "else:\n",
        "    print(f\"æ‰¾åˆ° {len(uploaded_files)} å€‹æ”¯æ´çš„æª”æ¡ˆï¼š\")\n",
        "    for file in uploaded_files:\n",
        "        print(f\"  - {os.path.basename(file)}\")\n",
        "    \n",
        "    # é–‹å§‹è½‰æ›\n",
        "    print(\"\\né–‹å§‹è½‰æ›éŸ³è¨Šç‚ºæ–‡å­—...\")\n",
        "    successful_conversions = []\n",
        "    \n",
        "    for i, file_path in enumerate(uploaded_files, 1):\n",
        "        print(f\"\\nè™•ç†ç¬¬ {i}/{len(uploaded_files)} å€‹æª”æ¡ˆ...\")\n",
        "        result = create_txt(file_path)\n",
        "        if result:\n",
        "            successful_conversions.append(result)\n",
        "    \n",
        "    print(f\"\\nğŸ‰ è™•ç†å®Œæˆï¼\")\n",
        "    print(f\"æˆåŠŸè½‰æ› {len(successful_conversions)}/{len(uploaded_files)} å€‹æª”æ¡ˆ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check_results"
      },
      "source": [
        "## 7. æŸ¥çœ‹çµæœ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "results_cell"
      },
      "outputs": [],
      "source": [
        "# æŸ¥çœ‹ä¸Šå‚³çš„æª”æ¡ˆ\n",
        "print(\"ğŸ“ ä¸Šå‚³çš„æª”æ¡ˆ:\")\n",
        "uploaded_files = get_supported_files(upload_dir)\n",
        "if uploaded_files:\n",
        "    for file in uploaded_files:\n",
        "        file_size = os.path.getsize(file) / (1024 * 1024)  # MB\n",
        "        print(f\"  - {os.path.basename(file)} ({file_size:.2f} MB)\")\n",
        "else:\n",
        "    print(\"  (æ²’æœ‰æª”æ¡ˆ)\")\n",
        "\n",
        "print(\"\\nğŸ“„ ç”Ÿæˆçš„æ–‡å­—æª”æ¡ˆ:\")\n",
        "txt_files = glob.glob(\"./subtitles/*.txt\")\n",
        "if txt_files:\n",
        "    for file in txt_files:\n",
        "        print(f\"  - {os.path.basename(file)}\")\n",
        "else:\n",
        "    print(\"  (æ²’æœ‰æª”æ¡ˆ)\")\n",
        "\n",
        "print(f\"\\nğŸ“Š çµ±è¨ˆ:\")\n",
        "print(f\"  - ä¸Šå‚³æª”æ¡ˆ: {len(uploaded_files)} å€‹\")\n",
        "print(f\"  - æ–‡å­—æª”æ¡ˆ: {len(txt_files)} å€‹\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preview_text"
      },
      "source": [
        "## 8. é è¦½æ–‡å­—å…§å®¹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preview_cell"
      },
      "outputs": [],
      "source": [
        "# é è¦½ç”Ÿæˆçš„æ–‡å­—æª”æ¡ˆå…§å®¹\n",
        "txt_files = glob.glob(\"./subtitles/*.txt\")\n",
        "\n",
        "if txt_files:\n",
        "    for file in txt_files:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"æª”æ¡ˆ: {os.path.basename(file)}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        \n",
        "        with open(file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "            # åªé¡¯ç¤ºå‰ 500 å€‹å­—å…ƒ\n",
        "            if len(content) > 500:\n",
        "                print(content[:500] + \"\\n\\n... (å…§å®¹éé•·ï¼Œåƒ…é¡¯ç¤ºå‰ 500 å­—å…ƒ)\")\n",
        "            else:\n",
        "                print(content)\n",
        "else:\n",
        "    print(\"æ²’æœ‰æ‰¾åˆ°æ–‡å­—æª”æ¡ˆï¼Œè«‹å…ˆåŸ·è¡Œæ­¥é©Ÿ 5 å’Œ 6\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_files"
      },
      "source": [
        "## 9. ä¸‹è¼‰çµæœæª”æ¡ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_cell"
      },
      "outputs": [],
      "source": [
        "# ä¸‹è¼‰æ–‡å­—æª”æ¡ˆåˆ°æœ¬åœ°\n",
        "import zipfile\n",
        "\n",
        "txt_files = glob.glob(\"./subtitles/*.txt\")\n",
        "\n",
        "if txt_files:\n",
        "    if len(txt_files) == 1:\n",
        "        # å¦‚æœåªæœ‰ä¸€å€‹æª”æ¡ˆï¼Œç›´æ¥ä¸‹è¼‰\n",
        "        print(f\"ä¸‹è¼‰æª”æ¡ˆ: {os.path.basename(txt_files[0])}\")\n",
        "        files.download(txt_files[0])\n",
        "    else:\n",
        "        # å¦‚æœæœ‰å¤šå€‹æª”æ¡ˆï¼Œæ‰“åŒ…æˆ zip æª”æ¡ˆ\n",
        "        zip_filename = \"transcriptions.zip\"\n",
        "        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "            for file in txt_files:\n",
        "                zipf.write(file, os.path.basename(file))\n",
        "        \n",
        "        print(f\"å·²æ‰“åŒ… {len(txt_files)} å€‹æª”æ¡ˆåˆ° {zip_filename}\")\n",
        "        files.download(zip_filename)\n",
        "else:\n",
        "    print(\"æ²’æœ‰æ‰¾åˆ°æ–‡å­—æª”æ¡ˆå¯ä¾›ä¸‹è¼‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch_upload"
      },
      "source": [
        "## 10. æ‰¹æ¬¡ä¸Šå‚³ (é¸ç”¨åŠŸèƒ½)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch_cell"
      },
      "outputs": [],
      "source": [
        "# å¦‚æœä½ æœ‰å¾ˆå¤šæª”æ¡ˆéœ€è¦è™•ç†ï¼Œå¯ä»¥å…ˆæ‰“åŒ…æˆ zip æª”ä¸Šå‚³\n",
        "# ç„¶å¾Œä½¿ç”¨é€™å€‹ cell ä¾†è§£å£“ç¸®\n",
        "\n",
        "print(\"ä¸Šå‚³ zip æª”æ¡ˆ (åŒ…å«å¤šå€‹éŸ³è¨Š/å½±ç‰‡æª”æ¡ˆ):\")\n",
        "uploaded_zip = files.upload()\n",
        "\n",
        "# è§£å£“ç¸®\n",
        "for zip_filename in uploaded_zip.keys():\n",
        "    if zip_filename.endswith('.zip'):\n",
        "        print(f\"æ­£åœ¨è§£å£“ç¸®: {zip_filename}\")\n",
        "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall(upload_dir)\n",
        "        print(f\"è§£å£“ç¸®å®Œæˆï¼\")\n",
        "        \n",
        "        # é¡¯ç¤ºè§£å£“ç¸®çš„æª”æ¡ˆ\n",
        "        extracted_files = get_supported_files(upload_dir)\n",
        "        print(f\"æ‰¾åˆ° {len(extracted_files)} å€‹æ”¯æ´çš„æª”æ¡ˆï¼š\")\n",
        "        for file in extracted_files:\n",
        "            print(f\"  - {os.path.basename(file)}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  {zip_filename} ä¸æ˜¯ zip æª”æ¡ˆï¼Œè·³é\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usage_notes"
      },
      "source": [
        "## ğŸ“ ä½¿ç”¨èªªæ˜\n",
        "\n",
        "### æ”¯æ´çš„æª”æ¡ˆæ ¼å¼\n",
        "- **éŸ³è¨Šæ ¼å¼**: MP3, WAV, FLAC, M4A, OGG, WMA, AAC\n",
        "- **å½±ç‰‡æ ¼å¼**: MP4, AVI, MOV, MKV, WMV, FLV, WebM\n",
        "\n",
        "### ä½¿ç”¨æµç¨‹\n",
        "1. åŸ·è¡Œæ­¥é©Ÿ 1-4 é€²è¡Œåˆå§‹åŒ–\n",
        "2. åŸ·è¡Œæ­¥é©Ÿ 5 ä¸Šå‚³æª”æ¡ˆ\n",
        "3. åŸ·è¡Œæ­¥é©Ÿ 6 è™•ç†æª”æ¡ˆ\n",
        "4. åŸ·è¡Œæ­¥é©Ÿ 7-9 æŸ¥çœ‹å’Œä¸‹è¼‰çµæœ\n",
        "\n",
        "### é€²éšåŠŸèƒ½\n",
        "- **æ‰¹æ¬¡è™•ç†**: å¯ä»¥ä¸€æ¬¡ä¸Šå‚³å¤šå€‹æª”æ¡ˆ\n",
        "- **ZIP ä¸Šå‚³**: å¦‚æœæª”æ¡ˆå¾ˆå¤šï¼Œå¯ä»¥æ‰“åŒ…æˆ zip æª”ä¸Šå‚³ (æ­¥é©Ÿ 10)\n",
        "- **æ¨¡å‹é¸æ“‡**: å¯ä»¥åœ¨æ­¥é©Ÿ 3 ä¸­ä¿®æ”¹æ¨¡å‹å¤§å°\n",
        "\n",
        "### æ¨¡å‹é¸æ“‡å»ºè­°\n",
        "- `\"tiny\"`: æœ€å¿«é€Ÿï¼Œä½†æº–ç¢ºåº¦æœ€ä½\n",
        "- `\"base\"`: é€Ÿåº¦å¿«ï¼Œæº–ç¢ºåº¦ä¸€èˆ¬\n",
        "- `\"small\"`: å¹³è¡¡é€Ÿåº¦å’Œæº–ç¢ºåº¦\n",
        "- `\"medium\"`: æ¨è–¦é¸æ“‡ï¼Œæº–ç¢ºåº¦è¼ƒé«˜\n",
        "- `\"large\"`: æœ€é«˜æº–ç¢ºåº¦ï¼Œä½†é€Ÿåº¦æœ€æ…¢\n",
        "\n",
        "### æ³¨æ„äº‹é …\n",
        "- æª”æ¡ˆå¤§å°é™åˆ¶ï¼šGoogle Colab æœ‰ä¸Šå‚³å¤§å°é™åˆ¶\n",
        "- è™•ç†æ™‚é–“ï¼šå–æ±ºæ–¼æª”æ¡ˆé•·åº¦å’Œæ¨¡å‹å¤§å°\n",
        "- èªè¨€è¨­å®šï¼šç›®å‰è¨­å®šç‚ºä¸­æ–‡ï¼Œå¯ä»¥ä¿®æ”¹æˆ–ç§»é™¤è®“æ¨¡å‹è‡ªå‹•åµæ¸¬\n",
        "- GPU åŠ é€Ÿï¼šå»ºè­°ä½¿ç”¨ GPU é‹ç®—ç’°å¢ƒæå‡é€Ÿåº¦\n",
        "\n",
        "### å¸¸è¦‹å•é¡Œ\n",
        "- **æª”æ¡ˆæ ¼å¼ä¸æ”¯æ´**: ç¢ºèªæª”æ¡ˆå‰¯æª”åæ˜¯å¦æ­£ç¢º\n",
        "- **è½‰æ›å¤±æ•—**: å¯èƒ½æ˜¯æª”æ¡ˆæå£æˆ–æ ¼å¼ç‰¹æ®Šï¼Œå˜—è©¦ç”¨å…¶ä»–è»Ÿé«”è½‰æ›æ ¼å¼\n",
        "- **è¨˜æ†¶é«”ä¸è¶³**: å˜—è©¦ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹æˆ–åˆ†æ‰¹è™•ç†"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "batch_upload"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}